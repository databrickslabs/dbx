environments:
  default:
    jobs:
      - name: "your-job-name"
        new_cluster:
          spark_version: "7.3.x-cpu-ml-scala2.12"
          node_type_id: "some-node-type"
          aws_attributes:
            first_on_demand: 0
            availability: "SPOT"
          num_workers: 2
        libraries: []
        max_retries: 0
        spark_python_task:
          python_file: "file://placeholder_1.py"
          parameters:
            - "file:fuse://placeholder_1.py"
            - "./placeholder_1.py"

custom:
  basic-cluster-props: &basic-cluster-props
    spark_version: "9.1.x-cpu-ml-scala2.12"
    node_type_id: "some-node-type"

  basic-static-cluster: &basic-static-cluster
    new_cluster:
      <<: *basic-cluster-props
      num_workers: 2

environments:
  default:
    jobs:
      - name: "your-job-name"
        tasks:
          - task_key: "first-task"
            <<: *basic-static-cluster
            spark_python_task:
              python_file: "./placeholder_1.py"
          - task_key: "second-task"
            <<: *basic-static-cluster
            spark_python_task:
              python_file: "./placeholder_2.py"
            depends_on:
              - task_key: "first-task"
        ## add job permissions
        permissions:
          access_control_list: ## acl list needs to be exhaustive
            - user_name: "some_user@example.com"
              permission_level: "IS_OWNER"
            - group_name: "some-user-group"
              permission_level: "CAN_VIEW"
        ## add notifications of job activities
        email_notifications:
          on_start:
            - "some_user@example.com"
          on_success:
            - "some_user@example.com"
          on_failure:
            - "some_user@example.com"
            - "some_group@example.com"
          no_alert_for_skipped_runs: false
        ## add job schedule
        schedule:
          quartz_cron_expression: "16 30 * * * ?"
          timezone_id: "America/Chicago"
          pause_status: "PAUSED"
